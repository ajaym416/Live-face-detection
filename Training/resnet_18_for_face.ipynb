{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_18_for_face.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EMrRRmz1428imQhyn5y1o7lJnxk-d6Oa",
      "authorship_tag": "ABX9TyNPWNyuhmzhIHTN/XLtsVz7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaym416/TreeleafAIchallenge/blob/main/resnet_18_for_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHR3yJTVIDui"
      },
      "source": [
        "import torch\r\n",
        "import os\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "from torchvision import datasets , models\r\n",
        "from torch.utils.data import Dataset , DataLoader\r\n",
        "import cv2\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "import logging\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "import torchvision\r\n",
        "import torch.nn as nn\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnpFguxLYZE"
      },
      "source": [
        "#for viewing our outputs and progress in tensorboard\r\n",
        "Writer = SummaryWriter(\"/content/drive/MyDrive/tree_ai/Output\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S1SAdIlO3tP"
      },
      "source": [
        "# %%python\n",
        "import logging\n",
        "log = logging.getLogger('tree_logger')\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO # allow INFO level messages to pass through the logger\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC5UJ7ZHg0mb"
      },
      "source": [
        "!unzip /content/drive/MyDrive/liveness_detection.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdRv1hkNMl4z",
        "outputId": "51996850-a40f-4d32-b36e-d11b5ad4c082"
      },
      "source": [
        "#make a list to contain the path of all the images to be used fot training\r\n",
        "fake_images_folder_path =\"/content/fake_images\"\r\n",
        "genuine_images_folder_path = \"/content/genuine_images\"\r\n",
        "log.info(f\"the number of fakes images is:{len(os.listdir(fake_images_folder_path))}\" )\r\n",
        "log.info(f\"the number of genuine images is:{len(os.listdir(genuine_images_folder_path))}\")\r\n",
        "folders=[fake_images_folder_path , genuine_images_folder_path]\r\n",
        "train_images_path=[]\r\n",
        "for folder_path in folders:\r\n",
        "  for images in os.listdir(folder_path):\r\n",
        "    if images[-3:] !='jpg':\r\n",
        "      #since all our images are in jpg , we are checking if there are any other files  other than the jpg images\r\n",
        "      log.info(images)\r\n",
        "    else:\r\n",
        "      file_path = os.path.join(folder_path,images)\r\n",
        "    train_images_path.append(file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tree_logger:the number of fakes images is:15093\n",
            "INFO:tree_logger:the number of genuine images is:14120\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKy_8swaJQ23"
      },
      "source": [
        "#Different Transformations for the data augmentation \r\n",
        "import torchvision.transforms as T\r\n",
        "def get_train_transform():\r\n",
        "  return (T.Compose([\r\n",
        "                     T.RandomHorizontalFlip(p=0.5),\r\n",
        "                     T.RandomRotation(15),\r\n",
        "                     T.RandomCrop(204,),\r\n",
        "                     T.ToTensor(),\r\n",
        "                     T.ColorJitter(brightness=(0.5,1.5), contrast=(0.5,1.5), saturation=(0.5,1.5), hue=(-0.1,0.1)),\r\n",
        "                    #  T.Normalize(mean=[0.4732, 0.3933, 0.3759], std=[0.2000, 0.1905, 0.1839])\r\n",
        "                     T.Normalize(mean=[0.4652, 0.3855, 0.3666],std=[0.2024, 0.1921, 0.1849])\r\n",
        "\r\n",
        "                    ]))\r\n",
        "def get_val_transform():\r\n",
        "  return (T.Compose([T.ToTensor(),\r\n",
        "                     ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iikqXCP1JOsN"
      },
      "source": [
        "class FaceDataset(Dataset):\r\n",
        "    def __init__(self,img_size = 224 ,train=True,test=False ,val_stride =10 ,sort_by_random =True,train_images =train_images_path,transforms=get_train_transform()):\r\n",
        "        self.img_size =img_size\r\n",
        "        self.train = train\r\n",
        "        self.val_stride = val_stride\r\n",
        "        self.sort_by_random= sort_by_random\r\n",
        "        self.train_images=train_images.copy()\r\n",
        "        self.transforms=transforms\r\n",
        "        self.test=test\r\n",
        "        if self.sort_by_random:\r\n",
        "          np.random.shuffle(self.train_images)\r\n",
        "        if self.train:\r\n",
        "          del self.train_images[::val_stride]\r\n",
        "        elif self.test:\r\n",
        "          self.train_images = self.train_images[::val_stride].copy()\r\n",
        "          del self.train_images[::2]\r\n",
        "        else:\r\n",
        "          self.train_images = self.train_images[::val_stride].copy()\r\n",
        "          self.train_images=self.train_images[::2]\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.train_images)\r\n",
        "    def __getitem__(self ,idx):\r\n",
        "        image_path = self.train_images[idx]\r\n",
        "        img = Image.open(image_path)\r\n",
        "        img = img.resize((self.img_size, self.img_size))\r\n",
        "        if (os.path.split(self.train_images[idx])[-2][-11:])=='fake_images':\r\n",
        "          label =np.eye(2)[0]\r\n",
        "          label = torch.tensor(label, dtype = torch.float32)\r\n",
        "        else:\r\n",
        "          label =np.eye(2)[1]\r\n",
        "          label = torch.tensor(label, dtype = torch.float32)\r\n",
        "                  \r\n",
        "        img = self.transforms(img)\r\n",
        "        return img, label\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXLbUAk0Mou7",
        "outputId": "cab5363c-923b-45bf-c43c-cfbe24e5b762"
      },
      "source": [
        "#Getting the training, validation and test_set\r\n",
        "train_data = FaceDataset()\r\n",
        "val_data = FaceDataset(train=False,transforms=get_val_transform())\r\n",
        "test_data = FaceDataset(train=False,test=True,transforms=get_val_transform())\r\n",
        "log.info(f\"train: {len(train_data)},val: {len(val_data)},test: {len(test_data)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tree_logger:train: 26291,val: 1461,test: 1461\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYsleTXvOIlT",
        "outputId": "132617a0-6a19-453f-ae1f-b1902f333c6b"
      },
      "source": [
        "#check if the GPU is availabe\r\n",
        "use_cuda =torch.cuda.is_available()\r\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\r\n",
        "log.info(f\"Training on device {device}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tree_logger:Training on device cuda.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFdxHMIPWTQn"
      },
      "source": [
        "#Data loader to load the data to the model by getting the data from dataset\r\n",
        "train_dl = torch.utils.data.DataLoader( \r\n",
        "    train_data,\r\n",
        "    batch_size=64,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=8,\r\n",
        ")\r\n",
        "val_dl=torch.utils.data.DataLoader( \r\n",
        "    val_data,\r\n",
        "    batch_size=64,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=8,\r\n",
        ")\r\n",
        "test_dl =torch.utils.data.DataLoader( \r\n",
        "    test_data,\r\n",
        "    batch_size=64,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=8,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvTVhqFDWd8o"
      },
      "source": [
        "#Display sample images used for training\r\n",
        "fig = plt.figure(figsize=(30, 30))\r\n",
        "columns = 4\r\n",
        "rows = 8\r\n",
        "images, labels = next(iter(train_dl))\r\n",
        "# ax enables access to manipulate each of subplots\r\n",
        "ax = []\r\n",
        "for i in range(columns*rows):\r\n",
        "  ax.append(fig.add_subplot(rows,columns,i+1))\r\n",
        "\r\n",
        "for i,img in enumerate(images):\r\n",
        "  if i>31:\r\n",
        "    break\r\n",
        "  ax[i].imshow(img.permute(1,2,0))\r\n",
        "  if labels[i][0]==0:\r\n",
        "    ax[i].set_title(\"genuine\")\r\n",
        "  else:\r\n",
        "    ax[i].set_title(\"Fake\" )\r\n",
        "\r\n",
        "plt.show()  # finally, render the plot\r\n",
        "image_grid = torchvision.utils.make_grid(images)\r\n",
        "Writer.add_image('Face',image_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtPxqPPnaG8n"
      },
      "source": [
        "# #To get the the mean and standard deviation of our dataset\r\n",
        "# train_data = FaceDataset()\r\n",
        "# loader = DataLoader(\r\n",
        "#     train_data,\r\n",
        "#     batch_size=64,\r\n",
        "#     num_workers=8,\r\n",
        "#     shuffle=False\r\n",
        "# )\r\n",
        "\r\n",
        "# mean = 0.\r\n",
        "# std = 0.\r\n",
        "# nb_samples = 0.\r\n",
        "# for data in loader:\r\n",
        "#   data ,labels =data\r\n",
        "#   batch_samples = data.size(0)\r\n",
        "#   data = data.view(batch_samples, data.size(1), -1)\r\n",
        "#   mean += data.mean(2).sum(0)\r\n",
        "#   std += data.std(2).sum(0)\r\n",
        "#   nb_samples += batch_samples\r\n",
        "\r\n",
        "# mean /= nb_samples\r\n",
        "# std /= nb_samples\r\n",
        "# print(mean, std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTcL410WxSdw"
      },
      "source": [
        "#get the pretrained model for transfer learning\r\n",
        "model = models.resnet18(pretrained=True)\r\n",
        "model.fc = nn.Sequential(\r\n",
        "    nn.Dropout(0.5),\r\n",
        "    nn.Linear(512, 2),\r\n",
        "    nn.Sigmoid()\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxoYv7x5II2I"
      },
      "source": [
        "# def Accuracy(preds, labels):\r\n",
        "#   preds =[[1 if preds[i][j]>= 0.5 else 0 for j in range(preds.shape[1])] for i in range(preds.shape[0])]\r\n",
        "#   total =len(preds)\r\n",
        "#   correct = np.sum([(preds[i]==np.array(torch.Tensor.tolist(labels)).astype(int)[i])[0] for i in range(len(labels))])\r\n",
        "#   return correct/total\r\n",
        "def Accuracy(preds, labels):\r\n",
        "  total =len(preds)\r\n",
        "  correct=0\r\n",
        "  value, preds = torch.max( preds, 1)\r\n",
        "  correct = torch.sum(preds == torch.argmax(labels,1)).item()\r\n",
        "  return correct/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6SipMtSyK9h"
      },
      "source": [
        "def train_one_epoch(train_data_loader,epoch):\r\n",
        "    \r\n",
        "    ### Local Parameters\r\n",
        "    epoch_loss = []\r\n",
        "    epoch_acc = []\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    ###Iterating over data loader\r\n",
        "    for i,(images, labels) in tqdm(enumerate(train_data_loader)):\r\n",
        "        #Loading images and labels to device\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        #Reseting Gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        #Forward\r\n",
        "        preds = model(images)\r\n",
        "        \r\n",
        "        #Calculating Loss\r\n",
        "        _loss = criterion(preds, labels)\r\n",
        "        loss = _loss.item()\r\n",
        "        epoch_loss.append(loss)\r\n",
        "        \r\n",
        "        #Calculating Accuracy\r\n",
        "        acc = Accuracy(preds, labels)\r\n",
        "        epoch_acc.append(acc)\r\n",
        "        \r\n",
        "        #Backward\r\n",
        "        _loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "    Writer.add_scalar(\"Training Loss\" ,loss,epoch)\r\n",
        "    Writer.add_scalar(\"Training Accuracy\" ,acc,epoch)\r\n",
        "\r\n",
        "    \r\n",
        "    ###Overall Epoch Results\r\n",
        "    end_time = time.time()\r\n",
        "    total_time = end_time - start_time\r\n",
        "    \r\n",
        "    epoch_loss = np.mean(epoch_loss)\r\n",
        "    epoch_acc = np.mean(epoch_acc)\r\n",
        "    \r\n",
        "    ###Storing results to logs\r\n",
        "    train_logs[\"loss\"].append(epoch_loss)\r\n",
        "    train_logs[\"accuracy\"].append(epoch_acc)\r\n",
        "    train_logs[\"time\"].append(total_time)\r\n",
        "    \r\n",
        "    return epoch_loss, epoch_acc, total_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rZwsATM07EQ"
      },
      "source": [
        "def val_one_epoch(val_data_loader,epoch, best_val_acc):\r\n",
        "    \r\n",
        "    ### Local Parameters\r\n",
        "    epoch_loss = []\r\n",
        "    epoch_acc = []\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    ###Iterating over data loader\r\n",
        "    for i,(images, labels) in enumerate(val_data_loader):\r\n",
        "        \r\n",
        "        #Loading images and labels to device\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        \r\n",
        "        #Forward\r\n",
        "        preds = model(images)\r\n",
        "        \r\n",
        "        #Calculating Loss\r\n",
        "        _loss = criterion(preds, labels)\r\n",
        "        loss = _loss.item()\r\n",
        "        epoch_loss.append(loss)\r\n",
        "        \r\n",
        "        #Calculating Accuracy\r\n",
        "        acc = Accuracy(preds, labels)\r\n",
        "        epoch_acc.append(acc)\r\n",
        "    Writer.add_scalar(\"Validation Loss\" ,loss,epoch)\r\n",
        "    Writer.add_scalar(\"Validation Accuracy\" ,acc,epoch)\r\n",
        "    \r\n",
        "    ###Overall Epoch Results\r\n",
        "    end_time = time.time()\r\n",
        "    total_time = end_time - start_time\r\n",
        "    \r\n",
        "    ###Acc and Loss\r\n",
        "    epoch_loss = np.mean(epoch_loss)\r\n",
        "    epoch_acc = np.mean(epoch_acc)\r\n",
        "    \r\n",
        "    ###Storing results to logs\r\n",
        "    val_logs[\"loss\"].append(epoch_loss)\r\n",
        "    val_logs[\"accuracy\"].append(epoch_acc)\r\n",
        "    val_logs[\"time\"].append(total_time)\r\n",
        "    \r\n",
        "    ###Saving best model\r\n",
        "    if epoch_acc > best_val_acc:\r\n",
        "        best_val_acc = epoch_acc\r\n",
        "        torch.save(model.state_dict(),\"/content/drive/MyDrive/liveness_detection_final_submission.pth\")\r\n",
        "        # torch.save(model.state_dict(),\"resnet18_best_face.pth\")\r\n",
        "        \r\n",
        "    return epoch_loss, epoch_acc, total_time, best_val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ty3M1_izqM-"
      },
      "source": [
        "def test_one_epoch(test_data_loader,epoch):\r\n",
        "    \r\n",
        "    ### Local Parameters\r\n",
        "    epoch_loss = []\r\n",
        "    epoch_acc = []\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    ###Iterating over data loader\r\n",
        "    for i,(images, labels) in enumerate(test_data_loader):\r\n",
        "        \r\n",
        "        #Loading images and labels to device\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        \r\n",
        "        #Forward\r\n",
        "        preds = model(images)\r\n",
        "        \r\n",
        "        #Calculating Loss\r\n",
        "        _loss = criterion(preds, labels)\r\n",
        "        loss = _loss.item()\r\n",
        "        epoch_loss.append(loss)\r\n",
        "        \r\n",
        "        #Calculating Accuracy\r\n",
        "        acc = Accuracy(preds, labels)\r\n",
        "        epoch_acc.append(acc)\r\n",
        "    Writer.add_scalar(\"Test Loss\" ,loss,epoch)\r\n",
        "    Writer.add_scalar(\"Test Accuracy\" ,acc,epoch)\r\n",
        "    \r\n",
        "    ###Overall Epoch Results\r\n",
        "    end_time = time.time()\r\n",
        "    total_time = end_time - start_time\r\n",
        "    \r\n",
        "    ###Acc and Loss\r\n",
        "    epoch_loss = np.mean(epoch_loss)\r\n",
        "    epoch_acc = np.mean(epoch_acc)\r\n",
        "    \r\n",
        "    ###Storing results to logs\r\n",
        "    test_logs[\"loss\"].append(epoch_loss)\r\n",
        "    test_logs[\"accuracy\"].append(epoch_acc)\r\n",
        "    test_logs[\"time\"].append(total_time)\r\n",
        "        \r\n",
        "    return epoch_loss, epoch_acc, total_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcSIwiUE1Sjn"
      },
      "source": [
        "# Optimizer\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\r\n",
        "# Learning Rate Scheduler\r\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\r\n",
        "#Loss Function\r\n",
        "criterion = nn.BCELoss()\r\n",
        "# Logs - Helpful for plotting after training finishes\r\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\r\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\r\n",
        "test_logs={\"loss\" : [], \"accuracy\" : [], \"time\" : []}\r\n",
        "# Loading model to device\r\n",
        "model.to(device)\r\n",
        "# No of epochs \r\n",
        "epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLj1AlUP0-Yv"
      },
      "source": [
        "best_val_acc = 0\r\n",
        "for epoch in range(epochs):\r\n",
        "    ###Training\r\n",
        "    loss, acc, _time = train_one_epoch(train_dl,epoch)\r\n",
        "    log.info(f\"Training : Epoch={epoch+1} , Loss={round(loss, 4)} , Acc= {round(acc, 4)} , Time{round(_time, 4)} \")\r\n",
        "    \r\n",
        "    ###Validation\r\n",
        "    loss,acc,_time,best_val_acc = val_one_epoch(val_dl,epoch, best_val_acc)\r\n",
        "    log.info(f\"Validation : Epoch={epoch+1} , Loss={round(loss, 4)} , Acc= {round(acc, 4)} , Time{round(_time, 4)} \")\r\n",
        "\r\n",
        "    ###Testing\r\n",
        "    loss,acc,_time = test_one_epoch(val_dl,epoch)\r\n",
        "    log.info(f\"Testing : Epoch={epoch+1} , Loss={round(loss, 4)} , Acc= {round(acc, 4)} , Time{round(_time, 4)} \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0uflO1p3Mq-"
      },
      "source": [
        "with open('/content/drive/MyDrive/tree_ai/train_logs.txt', 'w') as f:\r\n",
        "    print(train_logs, file=f)\r\n",
        "with open('/content/drive/MyDrive/tree_ai/val_logs.txt', 'w') as f:\r\n",
        "    print(train_logs, file=f)\r\n",
        "with open('/content/drive/MyDrive/tree_ai/test_logs.txt', 'w') as f:\r\n",
        "    print(train_logs, file=f)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1MouZlyz2K7"
      },
      "source": [
        "train_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zew35j-4EWT"
      },
      "source": [
        "val_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP3C31zE3q_d"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir /content/drive/MyDrive/tree_ai/Output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AURUGQzq4C2f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}